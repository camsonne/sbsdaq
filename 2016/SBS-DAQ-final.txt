SuperBigBite Data Acquisition Implementation
Alexandre Camsonne, Mark Jones
November 4, 2014

1

Overview of experiments

1.1

Overview of neutron form factor experiments

Both neutron form factor experiments measure quasi-free scattering on a nuclear
target. The standard Hall A BigBite Spectrometer is used to detect the scattered electrons. Neutrons and protons are detected in the hadron calorimeter
(HCAL) which is located behind the Super BigBite Spectrometer Magnet. The
Coordinate Detector (CDET) will be placed in front of the hadron calorimeter.
In the GEn experiment, the CDET will be used as a charge particle veto. In
the GMn experiment, the CDET will be used as a proton tagger. The trigger
for the experiments will be the BigBite spectrometer signel arm electron trigger
which is discussed in Section ??.
Due to the increase in luminosity, in comparison to earlier experiments, the
tracking detectors (MWPC) need to be upgraded to GEM chambers and the gas
Cherenkov detector upgraded to a highly segmented 510 photo-multiplier gas
Cherenkov detector (known as the GRINCH). The BigBite detector stack will
consist of: four GEM chambers (each covering 40x150 cm2 ), the GRINCH gas
cerenkov , one GEM chamber ( 60x200cm2 ), scintillator paddle array, preshower
and shower calorimeter. The scintillator array and preshower/shower calorimeter will be unchanged from previous experiments.
The preshower is 27 columns of two rows of lead glass which is placed perpendicular to the shower blocks. The shower calorimeter consist of 27 rows and
7 columns of lead glass blocks. The 243 channels of preshower and shower are
readout in FASTBUS 1881M 64 channel ADC modules. The standard Bigbite
scintillator array consists of one plane of scintillator paddles and can be used for
the experiments. For the planned Hall A A1N experiment, a 90 paddles scintillator array with PMTs on both ends is being built the University of Glasgow.
It is probable that it will be ready for the SBS neutron form factor experiments,
but it is not necessary for the experiments.
The 510 PMTs of the GRINCH gas Cherenkov detector will be input into
16 channel ampliflier/discriminator cards based which use the NINO chip. The
University of Glasgow has developed the cards and the cards have been bought.
The logical output from the cards will be readout in FASTBUS 1877S 96 channel
TDC modules.
1

The front 4 GEM chambers are being built by INFN group and are part of
the total of six that will be used as the front tracker for the proton form factor
(GEp) experiment. Each chamber consists of 3 GEM modules. Each GEM
module covers an area of 40x50 cm2 . The readout plane is pitched at 400 µm
and is readout using 128 channel APV25 chips. Each module is readout by a
total of 18 APV25 chips ( 8 along the 40 cm and 10 along the 50 cm). So a
GEM front chamber has 6912 channels which gives a total of 27648 channels for
the 4 GEM chambers. The APV25 chips will be readout by a VME64x/VXS
Multi-Purpose Digitizer (MPD) that was develop by an INFN group. It has
been used in previous experiments. Details are given in Section.
The rear GEM chamber is being built by the University of Virginia and is
part of the toal of 10 GEM chambers that will be used as the rear tracker for
the GEp experiment. Each chamber consist of 4 GEM modules. Each GEM
module covers an area of 60x50 cm2 and are combined into a chamber with an
area of 60x200 cm2 . The readout plane is pitched at 400 µm and two strips are
combined to reduce the number of readout channels. Readout is done using 128
channel APV25 chips. Each module is readout by a total of 12 APV25 chips (
6 along the 60 cm and 6 along the 50 cm). So a GEM rear chamber has 6144
channels which gives a total of 61,440 channels for the 10 GEM chambers. The
readout of the GEM rear chamber APV25 chips will use the same INFN MPD
electonics as the front GEM chambers.
The hadron calorimeter, HCAL, is a 12x24 block array which will be readout by a JLab FADC250, a 16-channel 12-bit Flash ADC sampling at 250 MHz.
For the neutron form factor experiments, the HCAL is not part of the trigger.
For the neutron form factor experiments, timing resolution is important at the
500ps level and the JLab FADC250 has demonstrated sub 300ps timing resolution. The FADC250 is readout through the VXS pipelined electronics which is
explained in Section 3.
The Coordinate Detector is two planes of scintillator. Each plane consist of
1176 scintillator bars. Each scintillator bar is readout by a wavelength shifting fiber. Fourteen of the WLS will be coupled to a 16 channel multianode
PMT. Each analog output of the PMT will be input to a 16 channel amplifier/discriminator card base on the NINO chip. The logic signals from the
NINO chip will go to FASTBUS 1877s 96 channel TDC modules. Since the
CDET is using only 14/16 channels , space is need for 2688 TDC channels (
16/14*2352).

1.2

Overview of proton form factor experiments

The proton form factor, GEp, experiment measures elastic electron-proton scattering. For electron detection, a large lead glass calorimeter, ECAL, will be used
with the Coordinate Detector, CDET, placed in front of ECAL. The CDET is
the same as used in the neutron form factor experiments except that it will be
arranged with one scintillator plane behind the other. The CDET is primarily
used to make a high precision measurement of the electron out-of-plane angle.
The proton will be detected in the SBS spectrometer which consist of front
2

tracker INFN GEMs, a polarimeter and the HCAL. The front tracker will consist of 6 INFN GEM chambers ( each GEM INFN chamber is 3 GEM modules of
40x50cm2 ). The polarimeter consists of two groups of 5 University of Virginia
GEM chambers (each UVa GEM chamber is 4 GEM modules of 60x50cm2 ).
The trigger will be a coincidence between the ECAL and HCAL.
The electronics for the front and rear GEM trackers will be the same as
used in the neutron form factor experiments. The CDET electronics will be the
same. The HCAL electronics will be still use the FADC250, but it will be part
of the trigger. Details of the trigger are discussed in Section ??.
ECAL is a large array of lead glass bars. In a previous proton form factor,
GEp3, experiment, 1784 lead bars were used in a calorimeter which was a mixture of 1024 blocks with 3.8x3.8 cm2 cross sectional area and 760 blocks with
4x4 cm2 cross sectional area. A larger pool of the same size lead glass bars is
available at Jefferson Lab. The electronics and cabling from that experiment
will be re-used. The lead glass bars will be readout out by FASTBUS 1881M
64 channel ADC modules. As done in the GEp3 experiment, the analog signals
from 8 blocks will be summed together in groups of 2x4 using custom built
“summing” modules. The “summing” modules have two sets of eight inputs.
Each set of eight inputs is summed together and six summed analog outputs for
each group of eight are available. In addition the “summing” module produces
the 16 individual analogs signal with an amplification of 4.2 that can be sent
to an ADC. The amount of electronics is estimated assuming a block size of
4x4 cm2 . Under this assumption, one needs 1776 blocks and would have 204
“group of 8” sums. One of “group of 8” analog signals would be sent to a discriminator and then a FASTBUS 1877S TDC. Other analog outputs from the
“group of 8” would be sent to additional FI/FO units to form summed analog
signal from a group of 32 blocks to be used in the ECAL trigger as explained in
Section 5.1.

1.3

2
2.1
2.1.1

Detector configuration summary

SuperBigBite electronics
CODA
Introduction

Jefferson Laboratory is using the Cebaf Online Data Acquisition (CODA) [6]
system for data taking. CODA is based on a main server interacting with a
database in which all the DAQ components update their status . The readout
crates host a single board computer running a Read Out Controller (ROC)
program which controls and reads out the data from the electronics. The ROCs
send the data through a standard network link usually ethernet to a computer
running the Event Builder program, which uses the data from the ROC to check
synchronization and build the event. Finally the event is sent to the Event
Recorder which puts the event into a file on the hard drive of the computer.

3

GEp Detectors
SBS Proton arm
Front tracker (6 GEM chambers)
Rear tracker (10 GEM chambers)
HCAL
Electron arm
ECAL
ECAL sums
CDET
GEn/GMn Detectors
SBS Proton arm
HCAL
CDet
BigBite Electron arm
PreShower/Shower
Scintillator
Gas Cerenkov
Front Tracker (4 GEM chambers)
Rear Tracker (1 GEM chamber)

2.1.2

Channels

Readout

Type

41,472
61,440
288

APV25 MPD
APV25 MPD
FADC 250

VME
VME
VME

1,776
204
2,688
Channels

ADCs 1881M
TDCs 1877S
TDCs 1877S
Readout

Fastbus
Fastbus
Fastbus
Type

288
2688

FADC 250
TDCs 1877S

VME
Fastbus

243
180
510
27,648
6,144

ADCs 1881M
ADCs 1877S
ADCs 1877S
APV25 MPD
APV25 MPD

Fastbus
Fastbus
Fastbus
VME
VME

CODA Hardware

In addition to the software a set of hardware components specific to CODA is
used in order to keep ensure event synchronization between all the components
each crate has a trigger interface ( TI board )[4] which sends the trigger signal
to the ROC program for the read out of the data. All the TI are linked to a
trigger supervisor TS[5] 1 board which takes the triggers and sends them to the
TI while monitoring the status of each TI to keep all the crates synchronized and
generates a Level 1 accept and Level 2 accept for the read out modules. The TS
also takes as input the front end busy of the modules to inhibit the triggering
if one module is not ready insuring synchronization between the modules. This
allows the TS module to buffering if the front-end has the capability. The
triggers and read out are then decorrelated which improve the deadtime since
a module can take triggers while being readout asynchronously. The TS has
a setting of the maximum of events which can be in the buffer it is set to the
smallest buffer available on the electronics ( usually 5 for Fastbus ). Since in
this mode modules can potentially get out of synchronization, a synchronization
event is set so that when a certain number of triggers is processed, the TS will
disable the triggers to empty the FIFO. If there any remaining events in the
FIFO a warning issue would be issued and the FIFOs would be cleared resynchronizing the modules.

4

VME CPU

TI
branches
to initiate
readout
on VME
CPUs

VME CPU

L1A
L2A
to
trigger
Front end modules

Trigger Interface

VME
modules

Trigger Interface

Trigger
input

VME
modules

VME
modules

Trigger Interface

VME CPU

Busy from modules

Figure 1: Standard CODA configuration

5

2.2

NINO amplifier discriminator boards

The discriminator card (Fig. 2) is based on the NINO chip [?], shown schematically in the blue-shaded box of Fig2. NINO was designed originally for time of
flight systems at the ALICE experiment. It is an 8-channel CMOS ASIC which
accepts differential input signals and provides LVDS output signals for timing.
The output width is dependent on the charge of the input signal and may be
stretched by an amount, dependent on the voltage applied to pin 9. This is
currently 1.25 V, which stretches by 10 ns. The threshold is set by applying
a differential DC voltage to pins 47 and 49. Pin 47 is fixed at 1.25 V and 49
is varied between 1.25 V (zero threshold) and 1.90 V (maximum). Ref. [?]
specifies that the threshold range is 10-100 fC and for the present application
this translates to a voltage levels in the few-mV range. For Hall-A/SBS exJLab Hall−A Discriminator

+Vcc +5V
10nF

J.R.M.Annand 9th Jan. 2012.
Updated 21st Jan. 2014

Amplify & Buffer MAXIM 4412
+Vcc +5V

MAXIM 9626

1 of 16 inputs

R4=4.7k

50−ohm coaxial
Set R1 = 0 Ohm R1

PMT Anode

−

+

R5=1k

+

−

1k

x1 A

few−ns rise/fall times

R2

50

R1

+

2.5V

LVDS
150R
Current 6mA
41
+LVDS OUTP1 − 8
LVDS
17,16,20,24,28,32,36,39
Pulse
Driver
Stretch

1 of 2 NINO chips
InP1 − 8
Input

75,01,74,70,62,58,54,57

15,18,22,26,30,34,38,37

InM1 − 8

−LVDS
Offset Control
Hysterisis

NINO

−ve

Disable

47

5
1.25V

Link

Vss

Adjust
45

Vcc

7
100k

+2.5V Vcc NINO

1k

10nF

1K

100nF

9

WO+
11

2 x 8−pair LVDS out

OUTM1 − 8

2 x 1−pair OR−8 out

13
WO−

1.25V = stretch pulse by
10ns

220

100k

Threshold Adjust

2k

Adjust

OR of 8
Enable

64
R3
66
Input Impedance
+ve
= 2 x R3
49
R3 = 50 Ohm
1.25 − 1.875V
GRINCH

5

MAXIM 9626
Output common−mode
voltage 2.5V

R2 Set R2 = 0 GRINCH

1M

Analogue Out

−
4.7k

1nF

73,76,72,68,60,56,53,55

10nF

100k

LM1118
1uF

10nF

1uF

+
4.7uF

10nF

+5V Power Supply

External threshold adjust

2k

Figure 2: Circuit diagram of the discriminator card. A schematic diagram of
the NINO chip is shown in the area shaded blue.
periments, the discriminator card will be used with PMT so that a front-end
circuit is required to convert the input signal from single ended to differential.
This is implemented using the MAXIM 9626, which is a unity-gain, low-noise,
low-distortion, fully-differential amplifier, with a bandwidth of 1.35 GHz. Resistors R1 allow the input impedance to be tuned to the input transmission line
and for 50 Ω coaxial cable R1 = 0 Ω. The differential output from the MAXIM
9626 feeds to the NINO input via capacitors which block the common-mode
voltage offset applied to the input circuit. Resistors R2 can potentially be used
to provide some attenuation of the pulse (to vary the threshold range), but for
GRINCH R2 = 0 Ω. Resistor R3 sets the input impedance of NINO and the
current value of 50 Ω sets the impedance to 100 Ω.
6

The front end also provides a buffer amplifier, suitable to drive charge digitizing hardware. This is required to calibrate the non-linear relation between
time-over-threshold and pulse amplitude. It is implemented using the MAXIM
4412 operational amplifier, which is moderately fast and relatively inexpensive.
The gain is (1 + R4/R5), nominally a factor 5.7.
Fig.3 is a photograph of the Mk-IV prototype card. Components are mounted
on a 5-layer PCB, designed and manufactured by ZOT Integrated Manufacturing based in Musselburgh, Scotland. Components are surface mounted, but
for the NINO chips standard solder masking techniques did not give a reliable
connection to the PCB, due to the fine pitch of the pads. The “balling” technique, whereby precise quantities of solder are deposited on the pads, solved this
problem. The card is designed for stand-alone operation (i.e. it does not reside
in an electronics crate), so that it can be mounted close to the detector using
the four mounting points at the corners of the card. The printed circuit board
houses 2 Mk1 (8-channel) NINO chips, associated front-end amplifier circuitry,
connectors for input signals and connectors for output analogue and LVDS logic
signals. Input cables can be connected, either by the 16 × 2-pin arrangement
shown in Fig.3, or alternatively hard soldered to the card. Provision of a connector to allow cables to be routed parallel to the plane of the card is to be
implemented on future production versions of the card. The output connectors
are standard 17-pair, 0.1” pitch IDC, commonly used with ECL logic.
The card operates from a single +5V supply which powers the operational
amplifiers and a voltage regulator which supplies 2.5 V to the NINO chips. The
amount of current drawn on the 5 V line is 1.25 A. Discriminator thresholds
can be adjusted by on-board potentiometers, or alternatively from an external
voltage source. This is chosen by the position of the jumpers on the “Link Ext
Thr” pins attached at the bottom left and right of the PCB. As shown, the PCB
has been configured to operate with external voltage thresholds, supplied via the
“Thr1” and “Thr2” connectors at the bottom of the card. When mounted, the
card will be covered by a metal sheet to shield from electromagnetic disturbance
and will include attachments to clamp input and output cables in place.
The NINO will be readout using Fastbus 1877S TDCs.

2.3
2.3.1

GEM readout
APV25

The GEM readout is carried out by the APV25 chip. It is a 128 channels ASICs
with pipeline depth of 192 samples sampling at 40 MHz giving a pipeline depth
of 4.8 µs ( limited to 4 µs for the hardware to perform correctly) . When a
trigger is issued the corresponding cells are frozen until they are readout while
the other cells are still being used reducing the dead time. For each trigger all
the data of 128 channels are transferred at 40 MHz rate in a multiplexed analog
format. Adding some header and event information 141 words are transmitted
for each trigger which gives a transfer time of 141x25ns = 3.6µs. In case of
high background several consecutive time samples can be sent in order to detect

7

Figure 3: The NINO-based amplifier-discriminator card. Dimensions are in
mm. Displayed is a prototype board. GRINCH and hodoscope cards will have
type-MCX coaxial connectors.
pile up, we plan to read 3 samples which gives a transfer time of 10.8 µs. This
allows dead-timeless operation for rates up to 90 KHz.
2.3.2

Multi Purpose Digitizer (MPD)

The readout planned to be used the the INFN Multi Purpose Digitizer (MPD).
It is a VME board with a 200 MHz FADC and signals to control the APV setup
and readout. It has 2 ports which can read up to 8 APVs each for a total of
16 APVs giving 2048 channels. For the GEp trackers 14 APVs will be read per
MPDs, the APV data is 130 24 bit words so the event size to be transferred for
3 samples is then :
130(wordsperAP V ) ∗ 3(samples) ∗ 14(AP V ) ∗ 3(bytes) = 16.38KB
Several readout schemes are possible with the MPD. The board complies
with the VME64X standard and can transfer up to 200 MB/s in sustained rate
using the VME320 protocol on the VME64X backplane 4.
When taking into account trigger processing and overhead of the DMA transaction, we reach an actual sustained sustained rate of about 100 MB/s.
At the assumed maximum rate of 5 KHz ( expected is 3 KHz ), that gives

8

APV25
x8

TI

VME CPU

SD

MPD
MPD
MPD
MPD
MPD
MPD
MPD
MPD
MPD

APV25
x8

MPD
VME64X or VXS crate
Figure 4: MPD readout using VME64X backplane

9

a raw data rate of 81.9 MB/s going into one single MPD from the APVs. In
the case of the GEp5, it was estimated that occupancy was around 60% which
would corresponds then to 49.2 MB/s per MPD after zero suppression which
would give 2 MPDs per crates. To reduce the data the deconvolution algorithm
will be implemented on the MPD to improve the timing resolution and reduce
the occupancy by effectively shortening the pulse by applying a weighted sum
similar to the on board deconvolution of the APV25 [7] to the multiple consecutive samples recorded, we expect a factor of at least 3 reduction of the accidental
background. Doing the deconvolution on the MPDs allows to have more flexibility in processing the data and is expected to have better performance than
the onboard one.
If the data reduction factor is not sufficient to transfer through the standard
VME backplane, we can also transfer the data through VXS port or through the
optical link of the MPD to allow parallel transfer of the data. In order to further
reduce the cost and amount of data recorded on tape a new readout scheme was
proposed taking advantage of the JLAB electronics and optical link feature of
the MPD. All the MPDs5 are sending data in parallel to the SSP and the SSP
reduced the area of interest to be recorded using geometrical informations from
othe HCAL and ECAL.
The MPD has 2 inputs to receive the trigger and an optional external clock.
One output of the MPD will have the board busy signal to be used to inhibit
the trigger in case the MPD buffers are filling up or if an APV raises an error
condition.

3

Pipelined electronics HCAL trigger

The hadron calorimeter will be read out by the JLAB pipelined electronics.
The central module for this system is the JLAB FADC250, a 16-channel 12-bit
FADC sampling at 250 MHz. The input signals are continuously recorded into
the memory with a memory depth up to 8 us. The system is thus dead timeless
as long as the trigger is generated before the memory rolls over and the event
of interest is overwritten. The Flash ADC has two separated data path. The
first one uses the new high speed serialized VME standard called VME switched
Serial (VXS). It allows full duplex point to point connection at up to 2.5 Gbps
per lane using the backplane central connector. Currently the FADC is using
two VXS lanes giving 5 Gbps of bandwidth. This allows to transfer a 16 bit word
from each FADC to a Crate Trigger Processor (CTP) board every 4 ns. Each
FADC being connected to The CTP via a 5 Gbps VXS link, the CTP uses up
to 16 FADC words from each FADC to form a 32-bit word every 4 ns which can
be a lower resolution sum of all the channels or a bit pattern of the channel hit
for example. The CTP board then sends the processed signals to a Sub-System
Processor (SSP) board via a 10 Gbps optical link which puts together all the
data from individual crates and computes the associated quantities which will
be used in the trigger. All the SSP boards send their processed information to
a Global Trigger Processor (GTP) which will produce the calorimeter trigger.

10

APV25
x8

4 to 1 optical link
4x 2.5 Gbit/s

up to 32 MPD
per
SSP

APV25
x8

MPD
VME crate

Figure 5: MPD readout using optical link readout

11

Once a trigger is generated, the full resolution data which is still in the pipeline
is readout out using the VME320 protocol at an average data rate of 200 MB/s.
The Flash ADC can run in different modes, it can either transfer all the samples
of the waveform which can be useful to study pileup effect and background or
process the data to give an integral over the length of the pulse. In both mode,
a threshold can be put on each individual channel to reduce the data.
In order to be able to do the clustering, the scheme used for the Heavy
Photon Search will be used. Instead of sending a sum of all the channels every 4
ns, it uses frames of 32 ns. If a pulse is above threshold, the pulse is integrated
over 32 ns for each FADC channel and the integral on 13 bit and a 3 bit time
are packed into a word and sent to the CTP at 8 Gbps. At the end of the 32
ns frame, the CTP will have all the amplitudes of each FADC channels and will
send them to the GTP using the optical link. The GTP having all the amplitude
of all the calorimeter, it can compute all the sums of adjacent blocks. A sum of
3×3 blocks was implemented for the heavy photon search experiment (HPS) in
Fig.7. In order to reduce the number of triggers coming from the background
this summing approach is chosen to improve the online pion rejection. A sum
over 4x4 adjacent blocks can be implemented in the same way as the HPS scheme
9.
Since we have 288 channels for the HCAL, 18 FADCs will be used using two
VXS crates Fig.8. The crate with all 16 FADCs will send its data ti the other
CTP through the SSP using the 10 Gb/s optical link. The second crate will
hold the two additional FADCs and a pipelined input register called VETROC
which can have up to 208 logic inputs which a 1 ns timing resolution, to send the
sums firing in the ECAL to the GTP to generate the L2 using the geometrical
matching of the HCAL with the ECAL. The total process will not take more
than 1 µs which is sufficiently fast for the APVs which have a look back of 4 µs.
The GEM readout 6 will also be done using the SSP in the second VXS crate,
if the amount of data is larger than 100 MB/s to transfer and additonnal crate
will be added to readout the SSP.

3.1

Fastbus

Fastbus is an electronics standard developed in the 1980’s. It can transfer
up to 10 Megawords per second with a 32 bit width which gives a maximum
theoretical throughput of 40 MB/s which translates in usual sustained rate of
15 MB/s. If the amount of data is greater than 15 MB/s, the modules will be
split between several crates allowing readout in parallel. Since we have a lot
of Fastbus equipment on hand. It will be used in order to reduce the costs for
the large number of detectors channels. The main readout is the Lecroy ADC
1881M a 13 bit ADC, with a 9 µs encoding time in 12 bit resolution and 12
µs in 13 bit resolution. The 1881M features a fast clear and is ready to take
another event after 1 µs. For signal requiring time measurement 1877S TDC
will be used, they have 96 channels per module. It is multihit up to 16 hits with
an event buffer of 8 events. It has an encoding time 1.7 µs plus 50 ns per hit
per channel giving a maximum encoding time of 78 µ. Both modules supports
12

L2A to FADCs

C
P
U

F
A
D
C

F
A
D
C

F
A
D
C

F F F F
A A A A
D D D D
C C C C

V
M
E

F
A
D
C

F
A
D
C

F
A
D
C

F
A
D
C

C
T SD
P

F
A
D
C

F
A
D
C

G
T SD
P

V
E
T
R
O
C

V
E S S
T S S
R P P
O
x2
C

F
A
D
C

F
A
D
C

F
A
D
C

TI

T1
ECAL

F
A
D
C

V
M
E

TS

C
P
U

F
A
D
C

T2 HCAL

L1A
to
Fastbus

V
M
E

L2

T
I

SD
board

MPD

MPD

MPD

MPD

MPD

MPD

MPD

L2

T
I

SD
board

S
S
P

TI

C
P
U

L2A
to
Fastbus

L2A
to
MPDs

TI

L2
MPD

MPD

MPD

MPD

MPD

MPD

T
I

MPD

SD
board

MPD

MPD

MPD

MPD

MPD

MPD

MPD

Busy
MPD

Figure 6: Pipelined electronics configuration of HCAL with MPD readout
through optical link

13

Start Frame 32 ns
Drop
last 4 bits

FADC

17 bits Σ

13 bits word
+
3 bits time in frame

16 bit
per channel

17 bits Σ

13 bits word
+
3 bits time in frame

16 bit
per channel

17 bits Σ

13 bits word
+
3 bits time in frame

16 bit
per channel

17 bits Σ

13 bits word
+
3 bits time in frame

16 bit
per channel

do
for
all
16 FADC
channels

send 2 channels
to CTP
in one 32 bit
word
every 4 ns
@
8 Gbps

Figure 7: Calorimeter clustering scheme using the HPS algorithm. All calorimeter signals are sent to the FADC. All 16 FADC channels integrals are sent to
the CTP in 32 ns

14

Figure 8: HCAL crate layout

15

FADC250

SD

SD

TIMASTER

CTP

CTP

TI

FADC250

FADC250

FADC250

FADC250

FADC250

FADC250

FADC250

FADC250

FADC250

FADC250

SSP

FADC250

FADC250

FADC250

FADC250

FADC250

FADC250

FADC250

FADC250
INPUT REGISTER

VME CPU
FADC250

VME CPU

VME CPU
SD
CTP
TI

Compute all sums of 4x4 adjacent blocks

Figure 9: All sum of 4x4 are computed, if one is above threshold L2 is generated

16

sparsification to reduce the non useful data before transfer. For each Fastbus
crate a Struck Fastbus Interface (SFI) is a Fastbus Master is controlled by a
standard VME controller which allows to control the Fastbus modules through
any VME CPU. It is needed in each Fastbus bin to control the Fastbus modules.
The L2 trigger will take 1 µs to be generated and with the fast clear time
we expect a L1 front end deadtime to be 2 µs.
In the case of the experiments using the BigBite spectrometer, ECAL will
be simply replaced by the BigBite shower. Each SFI can hold 2 VME boards,
one slot is used for the VME CPU and the VME TI will be placed in the second
slot.

4

Fastbus implementation

In order to improve the data transfer rate a large number of Fastbus crate is
going to be used. Right now we are planning to use 12 crates for the ECal 13
and 9 crates for the Coordinate Detector. One main challenge for the standard
Fastbus electronics is the GEp5 experiment where the L1A rate is going to be
of the order of 200 KHz. The calorimeter trigger is expected to be generated in
less than 1 µs and the ADCs requires 1 µs giving a front end deadtime of about
40 % at 200 KHz which is not acceptable. In order to reduce the front end
dead time, the signal will be passively split between 2 or 3 Fastbus modules, so
that when a module is busy encoding the next one is triggered eliminating the
front end busy from the Fastbus. In order to do that a slightly modified scheme
is used. The main trigger coming from the ECAL, is sent to the main TS at
around 200 KHz rate, the TS produce a prompt level 1 accept trigger which
will be used to trigger the non pipelined electronics. The L1A is processed by a
V1495 FPGA 10 board programmed as a prescaler, which take one signal input
and split the signal between 2 or more output ( number programmable up to 8
and in our case 2 or 3 ). The board is programmed to cycle through its output.
Three independent Fastbus setup will be in place with their own TS board 12
to keep each crates synchronized. The busy signal of each setup will be sent
to the V1495 which will generate a general busy signal sent to the main TS to
inhibit the trigger if the receiving Fastbus is not ready to receive a trigger. A
common 250MHz clock will be sent from the pipelined electronics to scalers in
each of the TS crate. This will provide a timestamp to be used as an absolute
reference for the time of an event. A copy of the L1A of each system will be fed
in each scalers giving a redundant check of the synchronization.
The signals from the calorimeter are split to generate the trigger and a copy
is sent through a 500 ns cable going into the Fastbus ADCs. The ECAL trigger
takes about 200 ns to be generated and is sent to TS with a high speed cable
of about 10 meters long for an additional. Each TS stage takes 50 ns. Which
leaves 150 ns to generate the gate for the Fastbus electronics.
Then the HCAL trigger is sent to the main TS after about 1 µs of processing
to act as the L2 trigger 11. If the L2 occurs withing 1 µs the readout of the
modules and the pipeline DAQ will start otherwise a fast clear is issue to the

17

NIM outputs
1 if N modulo 3 = 2
L1A N

1 if N modulo 3 = 1
1 if N modulo 3 = 0

Busy FB1
Busy FB2
Busy FB3
ECL outputs to TS
1 if N modulo 3 = 2
1 if N modulo 3 = 1
1 if N modulo 3 = 0

Busy for main TS

Figure 10: V1495 logic module programmed to distribute the L1A ( 200 KHz )
to the 3 different Fastbus DAQ

18

BigCal trigger

Busy

T1

BigCal

Busy

1881M

1881M

1881M

1881M

1881M

1881M

1881M

1881M

TI

V1495

FADC

T2
TI

FADC

FADC
BigCal
Sums
Trigger

SSP x2

1881M

SSP

1881M

CTP

1881M

VETROC

1881M

CTP

TS

CDet

1877S

1877S

1877S

1877S

1877S

1877S

T2

1877S

1877S

Optical link
100 MB
TI

1877S

250 MHz clock timestamp

Figure 11: Full layout of the DAQ system

19

MPD x 64

TS1

L1A1
S
c
C
T a
P
I l
U
e
r

Fastclock 250 MHz timestamp

V1495
T1 from ECAL
Busy1

TS

T2 from HCAL

TS2

L1A2
S
c

L1A

C
T a
P
I l
U
e

Busy

r

Busy2
L1A

TS3

L1A3
S
c
C
T a
P
I l
U
e
r

Busy3

Figure 12: Zoom on the TS for each Fastbus subsystem

20

L2A

TS1

to
CDET

A
T D
D C
C
1
1 8
8 8
7 1
7 M
S x8

CT
P I
U

A
T D
D C
C
1
1 8
8 8
7 1
7 M
S x8

CT
P I
U

T
D
C
1
8
7
7
S

A
D
C
1
8
8
1
M
x8

CT
P I
U

A
D
C
1
8
8
1
M
x8

L1A1

TS1

S
c
C
T a
P
I l
U
e
r

CT
P I
U

Gate from L1A

Busy1

Gate
to
CDET

T
D
C
1
8
7
7
S

to
CDET

to
CDET

T
D
C

A
D
C
1
8
8
1
M
x8

A
D
C

1
1 8
8 8
7 1
7 M
S x8

CT
P I
U

CT
P I
U

T
D
C
1
8
7
7
S

T
D
C

A
D
C
1
8
8
1
M
x8

A
D
C

1
1 8
8 8
7 1
7 M
S x8

CT
P I
U

CT
P I
U

A
D
C

T
D
C
1
8
7
7
S

T
D
C
1
8
7
7
S

1
8
8
1
M
x8

A
D
C
1
8
8
1
M
x8

CT
P I
U

CT
P I
U

A
D
C
1
8
8
1
M
x8

A
D
C
1
8
8
1
M
x8

TS2

Fast Clear L1A2

L1A2

S
c
C
T a
P
I l
U
e
r

CT
P I
U

Busy2
Gate

TS3

L1A3

Fast Clear

TS1

CT
P I
U

S
c

C
T a
P
I l
U
e
r

Busy3
Gate
Fast Clear

Figure 13: Fastbus ADC setup for ECAL

21

T
D
C

T
D
C

T
D
C

CT
1
P I
8
U
7
7
S
x 10

CT
1
P I
8
U
7
7
S
x 10

CT
1
P I
8
U
7
7
S
x 10

T
D
C

T
D
C

T
D
C

CT
1
P I
8
U
7
7
S
x 10

CT
1
P I
8
U
7
7
S
x 10

CT
1
P I
8
U
7
7
S
x 10

T
D
C
1
8
7
7
S
x 10

CT
P I
U

T
D
C

CT
P I
1
U
8
7
7
S
x 10

T
D
C

CT
P I
1
U
8
7
7
S
x 10

Figure 14: Fastbus TDC setup for CDet

22

Fastbus and another trigger can be take 1 µs later reducing the front end dead
time from the high L1 trigger rate.
Using this scheme the front end busy from the Fastbus will be reduced to
13 % since the input rate for the Fastbus is reduced by a factor of 3.
The data streams from the Fastbus DAQs and the pipelined DAQ will be
merged offline looking at the scalers and timestamp.
This setup will be used to readout ECAL or BigBite for the Neutron Form
Factor experiments.

5
5.1

GEp5 overview
ECAL calorimeter trigger

In the right figure, the groups of 32 blocks are indicated connecting group of
8 blocks by different colored squares. The group of 32 blocks overlap by two
groups of 8 in both horizontal and vertical directions. So most of the groups of 8
have to go to 4 groups of 32. At the edges the groups of 8 feed into two groups of
32. There are 204 groups of 32 are sums of 4 groups of 8 using a 4 input channel
linear FI/FO. The 228 groups of 32 would have to go into discriminators.
The calorimeter trigger will be the fast L1 trigger for the Fastbus, it is
generated in 200 ns. At the threshold of 80% of the maximum energy, we
foresee a maximum rate of 200 KHz. The trigger will use the HCAL as L2
trigger, the singles rates in HCAL was estimated to be 2 MHz. The L2 trigger
will be a cluster of 4x4 blocks over threshold and the L2 will also take as input
the sums from the L1 to make a geometrical matching of ECAL and HCAL
possible thanks to the overconstrained elastic kinematic. We expect to have a
3 KHz L2 coincidence trigger rate which will be used to trigger the FADC and
GEM readout.

5.2

Overall setup

An schematics giving an overview of the setup can be found in Fig.?? and more
details can be found in the experiment proposal E12-07-109: GEP/GMP [1]

5.3

Expected data rates

The expected trigger rate is 3 KHz. In order to be conservative the data rates
will be evaluated for a 5 KHz rate.
The GEM data is assumed with a 60% occupancy of the detector right after
common mode zero suppression. We assume that the deconvolution will reduce
the data by a factor of 3 and that the geometrical correlation will reduce the
GEM rate by at least another factor of 3. The actual data reduction factor will
be evaluated using simulated data.
The expected data rate of 143.1 MB/s is reasonable to record on tape. This
rate assumed no zero suppression on ECAL and HCAL recording full waveform
with 10 samples. Those can be set up to reduce further the data if needed.
23

xfp (cm)

Calo

xfp (cm)

Calo

150

60000

100

50000

100

50

40000

50

0

30000

-50

20000

-100

150

0

-50

-100
10000

-150

-150
0

-100

-80

-60

-40

-20

0

20

40
60
yfp (cm)

-100

-80

-60

-40

-20

0

20

40
60
yfp (cm)

Figure 15: The left plot is the distribution of elastic electrons in ECAL with
the black rectangles representing groups of 2x4 lead glass blocks. The right plot
demonstrates the scheme for make overlapping groups of 32 lead glass blocks to
be used in the ECAL trigger with details explained in text.

Detector
ECAL
HCAL
CDET
GEM FT
GEM RT
Total

Channels
1980
288
2688
41472
61440

Modules
96
18
84
24
30

Event size (KB)
7.92
11.52
2.195
25.05
36.86

Data rate ( MB/s)
39.6
57.6
10.98
127.18
187.2
422.6

Table 1: Data rate for proton for factor experiments with only GEM pedestal
suppression

24

AL

HC

r
M ke
GE rac
T
ar
Re

r
M ke
GE rac
tT
on
Fr

L

A
EC

S t
S B ne
ag
M
MPDs

CDet

Pipelined
DAQ

FB
TDC

FB
TDC

Analog
sum
ECAL

FB
TDC

ECAL T1 ( 200 KHz )
HCAL T2
FB
ADC

FB
ADC

FB
ADC

FB
ADC

TS
ECAL
500 ns delayed
Analog signal

Figure 16: GEp5 Layout

25

Detector
ECAL
HCAL
CDET
GEM FT
GEM RT
Total

Channels
1980
288
2688
41472
61440

Modules
96
18
84
24
30

Event size(KB)
7.92
11.52
2.195
25.05
36.86

Data rate ( MB/s)
39.6
57.6
10.98
14.13
20.8
143.1

Table 2: Data rate for proton for factor experiments with GEM deconvolution
and geometrical matching

6
6.1

Neutron form factor overview
BigBite shower trigger

The GEn and GMn experiments will use the BigBite shower/preshower 17 as
main trigger. The shower has a 7x27 geometry, all rows are summed in sum of
7 modules, the each sum of seven is split and sent to a sum of four modules
where it is added to another adjacent row in addition to the sum of the four
preshower module in front of the two shower rows. The total sum of 2 rows
of shower and 2 rows of preshower is discriminated and the shower trigger is
formed when one of those sum is above threshold18 . It is expected to be less
than 5 KHz so only one level of trigger is planned. If needed the coincidence
could easily implemented as for GEp5. The pipelined DAQ and GEM readout
will be triggered by the L1 shower trigger directly.

6.2

Overall setup

A schematics of the DAQ system for the neutron form factors experiments can
be found in Fig. 19 and more details can be found the the GEn proposal [2]
and GMn proposal [3]

6.3

Expected data rates

After deconvolution on the GEM data ( reduction by a factor of 3 ) We get
similar data rates as for GEp5 dominated by the HCAL data which could be
reduced by reading only time and amplitude instead of full waveform and implementing the pedestal suppression. The GEM rate is low enough to have all the
MPDs in one single VME64X crate. Using the coincidence trigger could reduce
further the data, we do not expect any issues as far as data rates are concerned
for the neutron form factor experiments.

26

Shower

PS3R

PS3L

PS2R

PS2L

PS1R

PS1L

Preshower

TDC "Sc01T"

P706

D

ADC "Sc01L"

Scintillator
A
PS776

Scintillator

A
A

PS776

PS776

A
PS776

A
PS776

A
A

PS776

50 Ω

50 Ω

ADC "P01L"
SPL
SPL

0.5/0.5

0.5/0.5

ADC "P01R"

ADC "P02L"
SPL
0.5/0.5

SPL
0.5/0.5

ADC "P02R"

ADC "P03L"
SPL
SPL

0.5/0.5

0.5/0.5

ADC "P03R"

Shower
Sh1/1
Sh1/2
Sh1/3
Sh1/4
Sh1/5
Sh1/6
Sh1/7

FI/O
L428F

Sh2/1
Sh2/2
Sh2/3
Sh2/4
Sh2/5
Sh2/6
Sh2/7

FI/O
L428F

Sh3/1
Sh3/2
Sh3/3
Sh3/4
Sh3/5
Sh3/6
Sh3/7

175

Sh
PSh

P758

AND/OR
37

20ns for cosmics
meas. on scope

TDC "TS01T"

LT
PS726

LT
PS726
180

4413*

4413*

D

D

NOTE: Electronic DT pulser should be fed into separate TDC channel as
an additional flag. The same pulse should be used to simulate coin. timing
with the HRS for Transversity.

Output is cap.
coupled inside
modified module

100 nF

100

TDC "TS02T"

TDC "PS01T"

100

AND/OR
P758
Level Translator
(PS726) here

NOTE:

OR

P755

OR

P757

OR

P755

OR

P757

25

"T6"
"Shower" Trigger

NOTE: This trigger better have a lower
threshold than the "regular" trigger if
you want TDC data.

"T1"
"Shower" Trigger

These modulse are in the ’Cerenkov’ Rack.

NOTE:
See Cerenkov diagram for
the full Shower+Cer(d2) Trigger,
and Cerenkov−related cable and
module counts.
EDT F/O also located in Cer. Rack.

Cluster 1 of 9
to overlap with
Cer. cluster 1 of 9

100

Electronic DT pulser won’t fire if the PS is needed in the AND
− one solution would be to force the coin. by changing the
P757 with a ’2of3’ capable module and inserting another
copy of the DT pulse there.

26 total

26 total

Build Clusters
for geom. overlap
with Cerenkov

NOTE: Shower clusters
are overlapped.

C
LC429A
D FI/FO

B

A

BigBite Shower/Pre−shower Trigger Logic

L428F

FI/O

ADC "TS01A"

Electronic DT
Pulser input

ADC "S1.1−S1.7"
S8

Sum7

ADC "PS01A"
Output is
cap. coupled

D
4413*

D
4413*

100 nF

D

PS726

LT

FI/O

4413*

LT

L428F

PS726

TDC "PS02T"

4413*

D

ADC "TS02A"

Electronic DT
Pulser input

ADC "S2.1−S2.7"
S8

Sum7

ADC "PS02A"

ADC "S3.1−S3.7"
S8

From other Sh+PS
Coinc. in this cluster

D
E

Cluster 2 of 9
to overlap with
Cer. cluster 2 of 9

Figure 17: BigBite electron shower analog sum trigger

Luke Myers
(modified from B. Sawatzky)
Jul. 3, 2014

Sc1R

Preshower

PS776

Sum7

From other Sh+PS
Coinc. in this cluster

F
LC429A
G FI/FO

27

Figure 18: Simplified BigBite electron shower analog sum trigger
Detector
BB Shower
BB Cerenkov
BB Timing scint.
CDET
HCAL
GEM FT
GEM RT
Total

Channels
243
510
180
2688
288
41472
6144

Modules
12
18
6
84
18
24
4

Event size (KB)
1.01
0.42
0.15
2.195
11.5
25.05
3.69

Data rate ( MB/s)
5.01
2.08
0.735
10.98
57.6
127.18
18.72
222.3

Table 3: Data rate for neutron for factor experiments without GEM deconvolution

28

Timing
hodoscope

CDet

AL
HC

GEM trackers

Ce
re
n
S t
S B ne
ag
M

S
pr how
es e
ho r
w
er
ko
v

Bi
gB

ite

m
ag

ne
t

MPDs

Pipelined
DAQ

FB
ADC

FB
TDC

FB
TDC

FB
TDC

FB
TDC

Analog
sum
Bigbite
shower
BigBite T1 ( 5 KHz )

FB
TDC

FB
TDC

TS
Shower
500 ns delayed
Analog signal

Figure 19: GEn Layout

29

Detector
BB Shower
BB Cerenkov
BB Timing scint.
CDET
HCAL
GEM FT
GEM RT
Total

Channels
243
510
180
2688
288
41472
6144

Modules
12
18
6
84
18
24
4

Event size (KB)
1.01
0.42
0.15
2.195
11.5
25.05
3.69

Data rate ( MB/s)
5.01
2.08
0.735
10.98
57.6
42.4
6.24
125.04

Table 4: Data rate for neutron for factor experiments without GEM deconvolution

7

Conclusion

The DAQ acquistion for SuperBigBite is reusing older electronics to read out the
ECAL, BigBite or the CDet. In order to reach a design goal of 200 KHz of L1
with reasonable deadtime, a triple stand alone Fastbus DAQ will be used. Two
GEM readout scheme were devised in addition to planning to implement the
deconvolution on the MPD readout itself, one through the standard VME64X
bus with a maximum transfer speed of about 100 MB/s which can be used
when occupancy is low in the chamber. The other one is a high speed transfer
scheme where all the MPDs are readout in parallel using the optical link and
sent to a SSP module which can read up to 32 boards in parallel ( 32 GBit/s
) allowing an additionnal reduction of the data using geometrical constraints
from other detectors. Finally the pipeline electronics allows to easily make a
clustering involving 4x4 blocks of the HCAL and will be used as L2 trigger for
the GEp5 experiment. Using the coincidence trigger, GEM deconvolution and
geometrical matching we expect to have reasonable data rate for GEp5. The
data rates are lower for the neutron form factor experiments thanks to a cleaner
electron trigger coming from the BigBite spectrometer and are not an issue as
well. The validation of the performance of the system will be done in 2015 with
a small scale Fastbus/pipelined DAQ/ GEM readout setup.

References
[1] E12-07-109: GEP/GMP http://hallaweb.jlab.org/collab/PAC/PAC34/
PR-09-016-gen.pdf
[2] E12-09-016:
GEN
PR12-07-109.pdf

http://www.jlab.org/exp_prog/proposals/07/

[3] E12-07-109: GEP/GMP http://hallaweb.jlab.org/collab/PAC/PAC34/
PR-09-019-gmn.pdf

30

[4] CODA TI board user manualhttps://coda.jlab.org/wiki/Downloads/
docs/manuals/VmeTIRManual.pdf
[5] CODA TS board user manualhttps://coda.jlab.org/wiki/Downloads/
docs/manuals//ts_manual.pdf
[6] CODA1.4
manual
https://coda.jlab.org/wiki/Downloads/docs/
manuals//coda1.4.pdf
[7] M. J. French, L. L. Jones, Q. Morrissey, A. Neviani, R. Turchetta, J. Fulcher,
G. Hall and E. Noah et al., Nucl. Instrum. Meth. A 466, 359 (2001).

31

